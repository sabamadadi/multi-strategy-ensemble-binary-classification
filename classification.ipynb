{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "91a0c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.svm import NuSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\n",
    "from catboost import Pool\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "ebf1a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv').drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "0030b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ctgan import CTGAN\n",
    "# from joblib import parallel_backend\n",
    "\n",
    "# real_data = df\n",
    "\n",
    "# # discrete_columns = [\n",
    "\n",
    "# #     'label'\n",
    "# # ]\n",
    "\n",
    "\n",
    "# from ctgan import CTGAN\n",
    "\n",
    "# # All 65 non-ID columns are binary, so everything is “discrete”\n",
    "# discrete_cols = [c for c in df.columns if c not in (\"ID\",)]\n",
    "\n",
    "# ctgan = CTGAN(\n",
    "#     # --- training ---\n",
    "#     epochs=200,                # smaller network ⇒ more epochs OK\n",
    "#     batch_size=100,             # 64 ≈ 1/9 of data; fits in RAM & keeps batches diverse\n",
    "#     verbose=True,\n",
    "\n",
    "#     # --- network sizes ---\n",
    "#     embedding_dim=32,          # 32 is plenty for binary categories (min(32, n_unique//2) = 1)\n",
    "#     generator_dim=(128, 128),  # 2 hidden layers, moderate width\n",
    "#     discriminator_dim=(128, 128),\n",
    "\n",
    "#     # --- optimisation ---\n",
    "#     generator_lr=2e-4,\n",
    "#     discriminator_lr=2e-4,\n",
    "#     generator_decay=1e-6,\n",
    "#     discriminator_decay=1e-6,\n",
    "#     discriminator_steps=1,     # default; >1 rarely helps on small data\n",
    "\n",
    "#     # --- regularisation tricks ---\n",
    "#     pac=5,                     # “PacGAN” mode combats mode-collapse with small data\n",
    "#     cuda=False                 # force CPU to bypass the CUDA DLL that triggered WinError 1455\n",
    "# )\n",
    "\n",
    "# # ctgan.fit(df[discrete_cols], discrete_cols)\n",
    "\n",
    "# # with parallel_backend('loky', n_jobs=1):  # or n_jobs=2\n",
    "\n",
    "# #     ctgan.fit(df, discrete_columns)\n",
    "\n",
    "# # synthetic_data = ctgan.sample(200)\n",
    "# # df = pd.concat([synthetic_data, df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "dcb085fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "570f214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "X_resampled[\"label\"] = y_resampled\n",
    "df=X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "5728fc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, counts = np.unique(y, return_counts=True)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(labels.astype(str), counts)\n",
    "plt.title('Training Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6397ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_scaled_df['label'] = X_resampled['label'] \n",
    "# df = X_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "cfab0f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature55</th>\n",
       "      <th>feature56</th>\n",
       "      <th>feature57</th>\n",
       "      <th>feature58</th>\n",
       "      <th>feature59</th>\n",
       "      <th>feature60</th>\n",
       "      <th>feature61</th>\n",
       "      <th>feature62</th>\n",
       "      <th>feature63</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0           1         1         0         1         1         1         1   \n",
       "1           0         1         1         1         0         1         1   \n",
       "2           1         1         1         1         0         0         1   \n",
       "3           1         0         0         0         1         0         0   \n",
       "4           1         1         1         1         1         1         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "787         0         0         0         0         0         0         0   \n",
       "788         0         0         0         0         0         0         1   \n",
       "789         0         1         0         0         0         0         0   \n",
       "790         0         0         0         0         0         0         0   \n",
       "791         1         0         1         0         1         0         0   \n",
       "\n",
       "     feature7  feature8  feature9  ...  feature55  feature56  feature57  \\\n",
       "0           0         1         1  ...          0          0          0   \n",
       "1           1         1         1  ...          1          1          1   \n",
       "2           1         0         1  ...          1          1          1   \n",
       "3           1         1         1  ...          0          0          0   \n",
       "4           0         1         1  ...          0          0          0   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "787         0         0         1  ...          0          0          0   \n",
       "788         1         0         0  ...          0          0          0   \n",
       "789         1         0         0  ...          0          0          0   \n",
       "790         0         0         0  ...          0          0          0   \n",
       "791         0         0         0  ...          0          0          0   \n",
       "\n",
       "     feature58  feature59  feature60  feature61  feature62  feature63  label  \n",
       "0            0          0          0          0          0          0      3  \n",
       "1            1          1          0          1          1          1      3  \n",
       "2            1          0          0          0          0          0      3  \n",
       "3            0          0          0          1          0          0      7  \n",
       "4            0          0          0          0          0          0      4  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "787          0          0          0          0          0          0     10  \n",
       "788          0          0          0          0          0          0     10  \n",
       "789          0          0          0          0          0          0     10  \n",
       "790          0          0          0          0          0          0     10  \n",
       "791          0          0          0          0          0          0     10  \n",
       "\n",
       "[792 rows x 65 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d5de16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_data.drop('ID', axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c75f4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop('ID', axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.drop('ID', axis=1, inplace=True)\n",
    "test.reset_index(drop =True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820bfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 25148.8535 | Test Output Shape: 0.17482517482517482\n",
      "Epoch 2/10 | Train Loss: 25.8210 | Test Output Shape: 0.1958041958041958\n",
      "Epoch 3/10 | Train Loss: 77.2264 | Test Output Shape: 0.26573426573426573\n",
      "Epoch 4/10 | Train Loss: 31.2363 | Test Output Shape: 0.2727272727272727\n",
      "Epoch 5/10 | Train Loss: 1.9371 | Test Output Shape: 0.27972027972027974\n",
      "Epoch 6/10 | Train Loss: 6.1311 | Test Output Shape: 0.27972027972027974\n",
      "Epoch 7/10 | Train Loss: 3.2185 | Test Output Shape: 0.27972027972027974\n",
      "Epoch 8/10 | Train Loss: 2.9205 | Test Output Shape: 0.27972027972027974\n",
      "Epoch 9/10 | Train Loss: 0.6825 | Test Output Shape: 0.27972027972027974\n",
      "Epoch 10/10 | Train Loss: 3.0799 | Test Output Shape: 0.27972027972027974\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>mlp_feat_502</th>\n",
       "      <th>mlp_feat_503</th>\n",
       "      <th>mlp_feat_504</th>\n",
       "      <th>mlp_feat_505</th>\n",
       "      <th>mlp_feat_506</th>\n",
       "      <th>mlp_feat_507</th>\n",
       "      <th>mlp_feat_508</th>\n",
       "      <th>mlp_feat_509</th>\n",
       "      <th>mlp_feat_510</th>\n",
       "      <th>mlp_feat_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.808503</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>-1.241154</td>\n",
       "      <td>-1.267655</td>\n",
       "      <td>-1.577396</td>\n",
       "      <td>5.611116</td>\n",
       "      <td>4.508015</td>\n",
       "      <td>0.086186</td>\n",
       "      <td>-1.108425</td>\n",
       "      <td>-0.726529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.529261</td>\n",
       "      <td>-0.392265</td>\n",
       "      <td>-7.434128</td>\n",
       "      <td>-2.554436</td>\n",
       "      <td>-2.429539</td>\n",
       "      <td>10.250200</td>\n",
       "      <td>4.910422</td>\n",
       "      <td>-5.607927</td>\n",
       "      <td>-2.806099</td>\n",
       "      <td>-1.514008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.383896</td>\n",
       "      <td>-0.305418</td>\n",
       "      <td>-6.676453</td>\n",
       "      <td>-2.329101</td>\n",
       "      <td>-2.367144</td>\n",
       "      <td>9.990671</td>\n",
       "      <td>5.232395</td>\n",
       "      <td>-4.900574</td>\n",
       "      <td>-2.496643</td>\n",
       "      <td>-1.316902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.277245</td>\n",
       "      <td>-4.029014</td>\n",
       "      <td>-1.233026</td>\n",
       "      <td>-3.121766</td>\n",
       "      <td>-1.981165</td>\n",
       "      <td>-3.471600</td>\n",
       "      <td>0.493428</td>\n",
       "      <td>0.321879</td>\n",
       "      <td>-1.943901</td>\n",
       "      <td>0.465479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.561965</td>\n",
       "      <td>-0.685580</td>\n",
       "      <td>-2.366149</td>\n",
       "      <td>-2.127692</td>\n",
       "      <td>-2.301685</td>\n",
       "      <td>12.764889</td>\n",
       "      <td>22.969774</td>\n",
       "      <td>-3.545784</td>\n",
       "      <td>-2.436770</td>\n",
       "      <td>-1.269199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.597370</td>\n",
       "      <td>-2.268068</td>\n",
       "      <td>-9.423201</td>\n",
       "      <td>-7.026139</td>\n",
       "      <td>-5.074817</td>\n",
       "      <td>-2.732399</td>\n",
       "      <td>1.126778</td>\n",
       "      <td>-4.491387</td>\n",
       "      <td>-3.379987</td>\n",
       "      <td>16.445610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.857017</td>\n",
       "      <td>-1.894309</td>\n",
       "      <td>-6.748350</td>\n",
       "      <td>-4.863965</td>\n",
       "      <td>-3.317651</td>\n",
       "      <td>-2.662413</td>\n",
       "      <td>-0.509084</td>\n",
       "      <td>-2.863708</td>\n",
       "      <td>-2.452474</td>\n",
       "      <td>10.224792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.578489</td>\n",
       "      <td>-2.035874</td>\n",
       "      <td>-6.954126</td>\n",
       "      <td>-4.636048</td>\n",
       "      <td>-3.466160</td>\n",
       "      <td>-1.909337</td>\n",
       "      <td>0.615776</td>\n",
       "      <td>-4.340552</td>\n",
       "      <td>-2.010994</td>\n",
       "      <td>10.894276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.834904</td>\n",
       "      <td>-2.059511</td>\n",
       "      <td>-7.230900</td>\n",
       "      <td>-4.981273</td>\n",
       "      <td>-3.532835</td>\n",
       "      <td>-2.444486</td>\n",
       "      <td>0.135550</td>\n",
       "      <td>-3.711625</td>\n",
       "      <td>-2.469263</td>\n",
       "      <td>11.160611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.322453</td>\n",
       "      <td>-0.503214</td>\n",
       "      <td>-2.608413</td>\n",
       "      <td>-3.066076</td>\n",
       "      <td>-2.422664</td>\n",
       "      <td>0.056418</td>\n",
       "      <td>2.612821</td>\n",
       "      <td>-0.198952</td>\n",
       "      <td>-1.493861</td>\n",
       "      <td>7.777944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 577 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0           1         1         0         1         1         1         1   \n",
       "1           0         1         1         1         0         1         1   \n",
       "2           1         1         1         1         0         0         1   \n",
       "3           1         0         0         0         1         0         0   \n",
       "4           1         1         1         1         1         1         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "787         0         0         0         0         0         0         0   \n",
       "788         0         0         0         0         0         0         1   \n",
       "789         0         1         0         0         0         0         0   \n",
       "790         0         0         0         0         0         0         0   \n",
       "791         1         0         1         0         1         0         0   \n",
       "\n",
       "     feature7  feature8  feature9  ...  mlp_feat_502  mlp_feat_503  \\\n",
       "0           0         1         1  ...     -0.808503      0.004178   \n",
       "1           1         1         1  ...     -1.529261     -0.392265   \n",
       "2           1         0         1  ...     -1.383896     -0.305418   \n",
       "3           1         1         1  ...     -1.277245     -4.029014   \n",
       "4           0         1         1  ...     -1.561965     -0.685580   \n",
       "..        ...       ...       ...  ...           ...           ...   \n",
       "787         0         0         1  ...     -2.597370     -2.268068   \n",
       "788         1         0         0  ...     -1.857017     -1.894309   \n",
       "789         1         0         0  ...     -1.578489     -2.035874   \n",
       "790         0         0         0  ...     -1.834904     -2.059511   \n",
       "791         0         0         0  ...     -1.322453     -0.503214   \n",
       "\n",
       "     mlp_feat_504  mlp_feat_505  mlp_feat_506  mlp_feat_507  mlp_feat_508  \\\n",
       "0       -1.241154     -1.267655     -1.577396      5.611116      4.508015   \n",
       "1       -7.434128     -2.554436     -2.429539     10.250200      4.910422   \n",
       "2       -6.676453     -2.329101     -2.367144      9.990671      5.232395   \n",
       "3       -1.233026     -3.121766     -1.981165     -3.471600      0.493428   \n",
       "4       -2.366149     -2.127692     -2.301685     12.764889     22.969774   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "787     -9.423201     -7.026139     -5.074817     -2.732399      1.126778   \n",
       "788     -6.748350     -4.863965     -3.317651     -2.662413     -0.509084   \n",
       "789     -6.954126     -4.636048     -3.466160     -1.909337      0.615776   \n",
       "790     -7.230900     -4.981273     -3.532835     -2.444486      0.135550   \n",
       "791     -2.608413     -3.066076     -2.422664      0.056418      2.612821   \n",
       "\n",
       "     mlp_feat_509  mlp_feat_510  mlp_feat_511  \n",
       "0        0.086186     -1.108425     -0.726529  \n",
       "1       -5.607927     -2.806099     -1.514008  \n",
       "2       -4.900574     -2.496643     -1.316902  \n",
       "3        0.321879     -1.943901      0.465479  \n",
       "4       -3.545784     -2.436770     -1.269199  \n",
       "..            ...           ...           ...  \n",
       "787     -4.491387     -3.379987     16.445610  \n",
       "788     -2.863708     -2.452474     10.224792  \n",
       "789     -4.340552     -2.010994     10.894276  \n",
       "790     -3.711625     -2.469263     11.160611  \n",
       "791     -0.198952     -1.493861      7.777944  \n",
       "\n",
       "[792 rows x 577 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# # Prepare data\n",
    "# X_train = df.drop(columns=[ \"label\"]).values.astype(np.float32)\n",
    "# y_train = df[\"label\"].values.astype(np.int64)\n",
    "# X_test = test.drop(columns=[\"index\"]).values.astype(np.float32)\n",
    "\n",
    "# # Define the MLP model\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dims=(1024,512,256,128, 64), output_dim=11): \n",
    "#         super().__init__()\n",
    "#         self.hidden = nn.Sequential(\n",
    "#             nn.Linear(input_dim, 1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 32),\n",
    "            \n",
    "#         )\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.output = nn.Sequential(\n",
    "#             nn.Linear(32, 32),\n",
    "#             # nn.ReLU(),\n",
    "#             # nn.Linear(256, 128),\n",
    "#             # nn.ReLU(),\n",
    "#             # nn.Linear(128, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, output_dim),\n",
    "\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.hidden(x)\n",
    "#         x = self.relu(x)\n",
    "#         return self.output(x)\n",
    "\n",
    "#     def extract_features(self, x):\n",
    "#         return self.hidden(x) \n",
    "\n",
    "# input_dim = X_train.shape[1]\n",
    "# mlp = MLP(input_dim=input_dim)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# mlp.to(device)\n",
    "\n",
    "# optimizer = optim.Adam(mlp.parameters(), lr=0.003)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# epochs = 10\n",
    "# batch_size = 16\n",
    "\n",
    "# train_loader = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)),\n",
    "#                           batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     mlp.train()\n",
    "#     for xb, yb in train_loader:\n",
    "#         xb, yb = xb.to(device), yb.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         logits = mlp(xb)\n",
    "#         loss = criterion(logits, yb) * 100000\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     # print(logits.argmax(1), yb)\n",
    "#     mlp.eval()\n",
    "#     with torch.no_grad():\n",
    "#         test_logits = mlp(torch.tensor(X_test).to(device))\n",
    "#         test_preds = torch.argmax(test_logits, dim=1).cpu().numpy()\n",
    "#         s = accuracy_score(np.array(test_logits.argmax(1).cpu()), np.array(y_test['target']))\n",
    "\n",
    "#     print(f\"Epoch {epoch + 1}/{epochs} | Train Loss: {loss.item():.4f} | Test Output Shape: {s}\")\n",
    "\n",
    "# mlp.eval()\n",
    "# with torch.no_grad():\n",
    "#     train_features = mlp.extract_features(torch.tensor(X_train).to(device)).cpu().numpy()\n",
    "#     test_features = mlp.extract_features(torch.tensor(X_test).to(device)).cpu().numpy()\n",
    "\n",
    "# train_feature_cols = [f\"mlp_feat_{i}\" for i in range(train_features.shape[1])]\n",
    "# test_feature_cols = [f\"mlp_feat_{i}\" for i in range(test_features.shape[1])]\n",
    "\n",
    "# for i, col in enumerate(train_feature_cols):\n",
    "#     df[col] = train_features[:, i]\n",
    "\n",
    "# for i, col in enumerate(test_feature_cols):\n",
    "#     test[col] = test_features[:, i]\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "44b07264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and labe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a9347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 288 out of 576\n"
     ]
    }
   ],
   "source": [
    "# selector_model = RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1)\n",
    "# selector = SelectFromModel(selector_model, threshold=\"median\")  # keep top 50% features\n",
    "\n",
    "# selector.fit(X, y)\n",
    "\n",
    "# # Transform datasets\n",
    "# X_selected_train = selector.transform(X)\n",
    "# X_selected_val = selector.transform(test.drop('index', axis=1))\n",
    "\n",
    "# # Show number of selected features\n",
    "# print(f\"Selected features: {X_selected_train.shape[1]} out of {X.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "4651b967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 22:52:22,545] A new study created in memory with name: bnb_opt\n",
      "[I 2025-05-30 22:52:22,597] Trial 0 finished with value: 0.36108590080407615 and parameters: {'alpha': 1.5569512147741704}. Best is trial 0 with value: 0.36108590080407615.\n",
      "[I 2025-05-30 22:52:22,647] Trial 1 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.045020046034829446}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:22,715] Trial 2 finished with value: 0.3661571530929066 and parameters: {'alpha': 0.00942566426921559}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:22,770] Trial 3 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.03925801068672394}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:22,816] Trial 4 finished with value: 0.3636095852241064 and parameters: {'alpha': 0.5670222078996099}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:22,861] Trial 5 finished with value: 0.3648913303080965 and parameters: {'alpha': 0.005066658948100161}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:22,905] Trial 6 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.025421179485129473}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:22,952] Trial 7 finished with value: 0.36361754637369637 and parameters: {'alpha': 0.19684541066149414}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:22,996] Trial 8 finished with value: 0.3661571530929066 and parameters: {'alpha': 0.010985364537423117}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,041] Trial 9 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.08424210996412872}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,090] Trial 10 finished with value: 0.35223310245999523 and parameters: {'alpha': 5.5140127948507915}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,138] Trial 11 finished with value: 0.3648913303080965 and parameters: {'alpha': 0.001175171365040608}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,185] Trial 12 finished with value: 0.36614919194331663 and parameters: {'alpha': 0.06180057131901748}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,233] Trial 13 finished with value: 0.36361754637369637 and parameters: {'alpha': 0.235208122337407}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,280] Trial 14 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.02390453588855766}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,327] Trial 15 finished with value: 0.3648913303080965 and parameters: {'alpha': 0.0020550086442544177}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,382] Trial 16 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.033870694620687675}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,431] Trial 17 finished with value: 0.3636095852241064 and parameters: {'alpha': 0.5234029964248473}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,477] Trial 18 finished with value: 0.3648913303080965 and parameters: {'alpha': 0.003991595431031328}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,523] Trial 19 finished with value: 0.36361754637369637 and parameters: {'alpha': 0.13402868721900466}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,570] Trial 20 finished with value: 0.3636095852241064 and parameters: {'alpha': 0.5195166828616907}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,616] Trial 21 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.024243395067121053}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,665] Trial 22 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.04041607501344493}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,713] Trial 23 finished with value: 0.3661571530929066 and parameters: {'alpha': 0.014583532127112579}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,759] Trial 24 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.08316359176727489}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,805] Trial 25 finished with value: 0.3661571530929066 and parameters: {'alpha': 0.015561789092257305}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,852] Trial 26 finished with value: 0.3648913303080965 and parameters: {'alpha': 0.006208582748461622}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,898] Trial 27 finished with value: 0.36614919194331663 and parameters: {'alpha': 0.060486999996935215}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:23,944] Trial 28 finished with value: 0.36361754637369637 and parameters: {'alpha': 0.1665435005127004}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,001] Trial 29 finished with value: 0.3648913303080965 and parameters: {'alpha': 0.002705837378730828}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,068] Trial 30 finished with value: 0.36106201735530613 and parameters: {'alpha': 3.2353300742561695}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,140] Trial 31 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.08168953782563114}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,211] Trial 32 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.04194385565108767}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,286] Trial 33 finished with value: 0.3610859008040761 and parameters: {'alpha': 0.3818734570410623}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,342] Trial 34 finished with value: 0.36486744685932654 and parameters: {'alpha': 1.3271350537136601}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,394] Trial 35 finished with value: 0.3661571530929066 and parameters: {'alpha': 0.007676868467092856}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,462] Trial 36 finished with value: 0.3661571530929066 and parameters: {'alpha': 0.020053506952989516}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,522] Trial 37 finished with value: 0.3648833691585065 and parameters: {'alpha': 0.1251092201710285}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,574] Trial 38 finished with value: 0.3661571530929066 and parameters: {'alpha': 0.010581669097133867}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,627] Trial 39 finished with value: 0.36361754637369637 and parameters: {'alpha': 0.28462700471144703}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,678] Trial 40 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.04612382028679503}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,728] Trial 41 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.02571655621222476}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,781] Trial 42 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.09191001530970583}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,832] Trial 43 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.02818135070148044}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,882] Trial 44 finished with value: 0.36614919194331663 and parameters: {'alpha': 0.06161301294388246}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,939] Trial 45 finished with value: 0.3661571530929066 and parameters: {'alpha': 0.01524077833772163}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:24,991] Trial 46 finished with value: 0.3661571530929066 and parameters: {'alpha': 0.011215341758126381}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:25,046] Trial 47 finished with value: 0.3648913303080965 and parameters: {'alpha': 0.004679485693504506}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:25,100] Trial 48 finished with value: 0.36361754637369637 and parameters: {'alpha': 0.19434779231431007}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:25,151] Trial 49 finished with value: 0.36741501472812677 and parameters: {'alpha': 0.053919706133097434}. Best is trial 1 with value: 0.36741501472812677.\n",
      "[I 2025-05-30 22:52:25,153] A new study created in memory with name: xgb_opt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB best params: {'alpha': 0.045020046034829446}\n",
      "BernoulliNB best CV accuracy: 0.36741501472812677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 22:52:39,057] Trial 0 finished with value: 0.5099912427354509 and parameters: {'n_estimators': 417, 'max_depth': 11, 'learning_rate': 0.013217170431888397, 'subsample': 0.7326041691404042, 'colsample_bytree': 0.6673856336579235}. Best is trial 0 with value: 0.5099912427354509.\n",
      "[I 2025-05-30 22:52:50,213] Trial 1 finished with value: 0.5049677573441606 and parameters: {'n_estimators': 563, 'max_depth': 6, 'learning_rate': 0.09661690853354525, 'subsample': 0.6779997140954253, 'colsample_bytree': 0.6278229815829457}. Best is trial 0 with value: 0.5099912427354509.\n",
      "[I 2025-05-30 22:53:13,811] Trial 2 finished with value: 0.5175941405939017 and parameters: {'n_estimators': 697, 'max_depth': 10, 'learning_rate': 0.014237002804084352, 'subsample': 0.9466494970293257, 'colsample_bytree': 0.6907650804262255}. Best is trial 2 with value: 0.5175941405939017.\n",
      "[I 2025-05-30 22:53:26,088] Trial 3 finished with value: 0.5050075630921105 and parameters: {'n_estimators': 588, 'max_depth': 12, 'learning_rate': 0.11127857360648621, 'subsample': 0.6385751094190725, 'colsample_bytree': 0.8761775057259154}. Best is trial 2 with value: 0.5175941405939017.\n",
      "[I 2025-05-30 22:53:32,532] Trial 4 finished with value: 0.4545020300931455 and parameters: {'n_estimators': 411, 'max_depth': 3, 'learning_rate': 0.01590539555395603, 'subsample': 0.6772130644463161, 'colsample_bytree': 0.76749638668504}. Best is trial 2 with value: 0.5175941405939017.\n",
      "[I 2025-05-30 22:53:47,170] Trial 5 finished with value: 0.49106759016001905 and parameters: {'n_estimators': 892, 'max_depth': 6, 'learning_rate': 0.1440264932973326, 'subsample': 0.969320179765312, 'colsample_bytree': 0.9409353268711242}. Best is trial 2 with value: 0.5175941405939017.\n",
      "[I 2025-05-30 22:54:02,247] Trial 6 finished with value: 0.5113127935673912 and parameters: {'n_estimators': 781, 'max_depth': 4, 'learning_rate': 0.06410652889887082, 'subsample': 0.6279874133675842, 'colsample_bytree': 0.5886332128543309}. Best is trial 2 with value: 0.5175941405939017.\n",
      "[I 2025-05-30 22:54:08,584] Trial 7 finished with value: 0.5037098957089403 and parameters: {'n_estimators': 330, 'max_depth': 8, 'learning_rate': 0.18729767962884, 'subsample': 0.819821478827617, 'colsample_bytree': 0.9226999229090538}. Best is trial 2 with value: 0.5175941405939017.\n",
      "[I 2025-05-30 22:54:23,176] Trial 8 finished with value: 0.5062733858769206 and parameters: {'n_estimators': 631, 'max_depth': 6, 'learning_rate': 0.06783712207935627, 'subsample': 0.9355709060349036, 'colsample_bytree': 0.7090814656095674}. Best is trial 2 with value: 0.5175941405939017.\n",
      "[I 2025-05-30 22:54:33,914] Trial 9 finished with value: 0.5037337791577104 and parameters: {'n_estimators': 493, 'max_depth': 6, 'learning_rate': 0.06902944743738806, 'subsample': 0.9452622302357567, 'colsample_bytree': 0.9564937828132731}. Best is trial 2 with value: 0.5175941405939017.\n",
      "[I 2025-05-30 22:54:33,916] A new study created in memory with name: brf_opt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB best params: {'n_estimators': 697, 'max_depth': 10, 'learning_rate': 0.014237002804084352, 'subsample': 0.9466494970293257, 'colsample_bytree': 0.6907650804262255}\n",
      "XGB best CV accuracy: 0.5175941405939017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 22:54:54,714] Trial 0 finished with value: 0.45699386991481566 and parameters: {'n_estimators': 998, 'max_depth': 32, 'min_samples_split': 15, 'min_samples_leaf': 9, 'bootstrap': False}. Best is trial 0 with value: 0.45699386991481566.\n",
      "[I 2025-05-30 22:55:02,503] Trial 1 finished with value: 0.4671443356420667 and parameters: {'n_estimators': 323, 'max_depth': 43, 'min_samples_split': 17, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 1 with value: 0.4671443356420667.\n",
      "[I 2025-05-30 22:55:07,535] Trial 2 finished with value: 0.4544861077939655 and parameters: {'n_estimators': 209, 'max_depth': 32, 'min_samples_split': 15, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 1 with value: 0.4671443356420667.\n",
      "[I 2025-05-30 22:55:11,968] Trial 3 finished with value: 0.45704959796194566 and parameters: {'n_estimators': 190, 'max_depth': 16, 'min_samples_split': 19, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 1 with value: 0.4671443356420667.\n",
      "[I 2025-05-30 22:55:35,252] Trial 4 finished with value: 0.4443834089642545 and parameters: {'n_estimators': 981, 'max_depth': 33, 'min_samples_split': 4, 'min_samples_leaf': 6, 'bootstrap': True}. Best is trial 1 with value: 0.4671443356420667.\n",
      "[I 2025-05-30 22:55:57,173] Trial 5 finished with value: 0.5277207228723828 and parameters: {'n_estimators': 973, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 5 with value: 0.5277207228723828.\n",
      "[I 2025-05-30 22:56:01,949] Trial 6 finished with value: 0.4456651540482445 and parameters: {'n_estimators': 208, 'max_depth': 48, 'min_samples_split': 17, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 5 with value: 0.5277207228723828.\n",
      "[I 2025-05-30 22:56:20,552] Trial 7 finished with value: 0.46964413661332693 and parameters: {'n_estimators': 973, 'max_depth': 43, 'min_samples_split': 10, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 5 with value: 0.5277207228723828.\n",
      "[I 2025-05-30 22:56:38,668] Trial 8 finished with value: 0.4380542950402038 and parameters: {'n_estimators': 748, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 5 with value: 0.5277207228723828.\n",
      "[I 2025-05-30 22:56:49,094] Trial 9 finished with value: 0.5024918398216702 and parameters: {'n_estimators': 537, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 5 with value: 0.5277207228723828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancedRF best params: {'n_estimators': 973, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}\n",
      "BalancedRF best CV accuracy: 0.5277207228723828\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "X = df.drop(columns=[ 'label'])\n",
    "y = df['label']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def cross_val_score_model(model, X, y):\n",
    "    scores = []\n",
    "    for train_idx, valid_idx in cv.split(X, y):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_valid)\n",
    "        scores.append(accuracy_score(y_valid, preds))\n",
    "    return np.mean(scores)\n",
    "\n",
    "def objective_bnb(trial):\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
    "    model = BernoulliNB(alpha=alpha)\n",
    "    return cross_val_score_model(model, X, y)\n",
    "\n",
    "study_bnb = optuna.create_study(direction='maximize', study_name='bnb_opt')\n",
    "study_bnb.optimize(objective_bnb, n_trials=50)\n",
    "print('BernoulliNB best params:', study_bnb.best_params)\n",
    "print('BernoulliNB best CV accuracy:', study_bnb.best_value)\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'mlogloss'\n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    return cross_val_score_model(model, X, y)\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize', study_name='xgb_opt')\n",
    "study_xgb.optimize(objective_xgb, n_trials=10)\n",
    "print('XGB best params:', study_xgb.best_params)\n",
    "print('XGB best CV accuracy:', study_xgb.best_value)\n",
    "\n",
    "def objective_brf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 50),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    model = BalancedRandomForestClassifier(**params)\n",
    "    return cross_val_score_model(model, X, y)\n",
    "\n",
    "study_brf = optuna.create_study(direction='maximize', study_name='brf_opt')\n",
    "study_brf.optimize(objective_brf, n_trials=10)\n",
    "print('BalancedRF best params:', study_brf.best_params)\n",
    "print('BalancedRF best CV accuracy:', study_brf.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0434ffde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.045020046034829446}"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_bnb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "9efc88bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature55</th>\n",
       "      <th>feature56</th>\n",
       "      <th>feature57</th>\n",
       "      <th>feature58</th>\n",
       "      <th>feature59</th>\n",
       "      <th>feature60</th>\n",
       "      <th>feature61</th>\n",
       "      <th>feature62</th>\n",
       "      <th>feature63</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0           1         1         0         1         1         1         1   \n",
       "1           0         1         1         1         0         1         1   \n",
       "2           1         1         1         1         0         0         1   \n",
       "3           1         0         0         0         1         0         0   \n",
       "4           1         1         1         1         1         1         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "787         0         0         0         0         0         0         0   \n",
       "788         0         0         0         0         0         0         1   \n",
       "789         0         1         0         0         0         0         0   \n",
       "790         0         0         0         0         0         0         0   \n",
       "791         1         0         1         0         1         0         0   \n",
       "\n",
       "     feature7  feature8  feature9  ...  feature55  feature56  feature57  \\\n",
       "0           0         1         1  ...          0          0          0   \n",
       "1           1         1         1  ...          1          1          1   \n",
       "2           1         0         1  ...          1          1          1   \n",
       "3           1         1         1  ...          0          0          0   \n",
       "4           0         1         1  ...          0          0          0   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "787         0         0         1  ...          0          0          0   \n",
       "788         1         0         0  ...          0          0          0   \n",
       "789         1         0         0  ...          0          0          0   \n",
       "790         0         0         0  ...          0          0          0   \n",
       "791         0         0         0  ...          0          0          0   \n",
       "\n",
       "     feature58  feature59  feature60  feature61  feature62  feature63  label  \n",
       "0            0          0          0          0          0          0      3  \n",
       "1            1          1          0          1          1          1      3  \n",
       "2            1          0          0          0          0          0      3  \n",
       "3            0          0          0          1          0          0      7  \n",
       "4            0          0          0          0          0          0      4  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "787          0          0          0          0          0          0     10  \n",
       "788          0          0          0          0          0          0     10  \n",
       "789          0          0          0          0          0          0     10  \n",
       "790          0          0          0          0          0          0     10  \n",
       "791          0          0          0          0          0          0     10  \n",
       "\n",
       "[792 rows x 65 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "bc31fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(784, 512, 128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "\n",
    "              \n",
    "\n",
    "# bnb_model =\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    # ('svc', SVC(gamma=\"auto\", probability=True, random_state=42)),\n",
    "#             'svc_li': SVC(kernel=\"linear\", gamma=\"auto\", probability=True, random_state=self.random_state),\n",
    "            ('svc_po', SVC(kernel=\"poly\", gamma=\"auto\", probability=True, random_state=42)),\n",
    "            # ('svc_si', SVC(kernel=\"sigmoid\", gamma=\"auto\", probability=True, random_state=42)),\n",
    "    ('bnb',  BernoulliNB(alpha = 0.51)),\n",
    "    ('bnb2',  BernoulliNB(alpha = 0.8)),\n",
    "    ('bnb3',  BernoulliNB(**study_bnb.best_params)),\n",
    "    ('bnb4',  BernoulliNB(alpha = 1.5)),\n",
    "    ('bnb5',  BernoulliNB(alpha = 2)),\n",
    "    # ('bnb6',  BernoulliNB(alpha = 0.5)),\n",
    "\n",
    "\n",
    "\n",
    "    # ('lr', LogisticRegression(max_iter=10000, random_state=42, n_jobs=-1)),\n",
    "    ('xgb', XGBClassifier(**study_xgb.best_params)),\n",
    "    # ('lgb', lgb.LGBMClassifier(**lgb_params)),\n",
    "    # ('cat', CatBoostClassifier(**cb_params)),\n",
    "    ('brf', BalancedRandomForestClassifier(**study_brf.best_params)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200,max_depth = 20 , random_state=42)),\n",
    "    # ('rf2', RandomForestClassifier(n_estimators=300,max_depth = 30 , random_state=42)),\n",
    "    # ('rf3', RandomForestClassifier(n_estimators=400,max_depth = 40 , random_state=42)),\n",
    "    ('rf4', RandomForestClassifier(n_estimators=280,max_depth = 30 , min_samples_leaf=1 , min_samples_split=11 , bootstrap=False ,   random_state=42)),\n",
    "    # ('mlp',  mlp_logits)\n",
    "], voting='soft')\n",
    "\n",
    "voting_clf.fit(X, y)\n",
    "\n",
    "y_pred = voting_clf.predict(pd.DataFrame(test).drop('index', axis=1))\n",
    "\n",
    "# accuracy = accuracy_score(y_test['target'], y_pred)\n",
    "# report = classification_report(y_test['target'], y_pred, output_dict=False)\n",
    "\n",
    "# accuracy, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred.to_csv('y_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "2ec254d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled.drop('label', axis=1))\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "82719cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 23:42:35,138] A new study created in memory with name: no-name-4f2d0ae0-d15e-4ed4-871b-93a14d54919e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 23:42:41,205] Trial 0 finished with value: 0.38888888888888884 and parameters: {'xgb_n_estimators': 284, 'xgb_max_depth': 6, 'xgb_lr': 0.0018397321885300403, 'xgb_subsample': 0.7832803242256716, 'xgb_cbt': 0.5432037586367516, 'xgb_alpha': 4.689838029406961e-06, 'xgb_lambda': 0.011519915693040549, 'brf_n_estimators': 1174, 'brf_max_depth': 25, 'brf_min_samples_split': 9, 'brf_min_samples_leaf': 9, 'brf_bootstrap': True}. Best is trial 0 with value: 0.38888888888888884.\n",
      "[I 2025-05-30 23:42:50,938] Trial 1 finished with value: 0.4065656565656566 and parameters: {'xgb_n_estimators': 919, 'xgb_max_depth': 5, 'xgb_lr': 0.004474623508189751, 'xgb_subsample': 0.5266512312205076, 'xgb_cbt': 0.9381464539826139, 'xgb_alpha': 0.0067809368757091055, 'xgb_lambda': 5.834813073915649e-07, 'brf_n_estimators': 2312, 'brf_max_depth': 43, 'brf_min_samples_split': 13, 'brf_min_samples_leaf': 9, 'brf_bootstrap': True}. Best is trial 1 with value: 0.4065656565656566.\n",
      "[I 2025-05-30 23:42:56,707] Trial 2 finished with value: 0.39015151515151514 and parameters: {'xgb_n_estimators': 397, 'xgb_max_depth': 13, 'xgb_lr': 0.45982230473819696, 'xgb_subsample': 0.6153530103388323, 'xgb_cbt': 0.47047034687306444, 'xgb_alpha': 6.87906445042127, 'xgb_lambda': 0.2366013282614094, 'brf_n_estimators': 1348, 'brf_max_depth': 46, 'brf_min_samples_split': 10, 'brf_min_samples_leaf': 8, 'brf_bootstrap': True}. Best is trial 1 with value: 0.4065656565656566.\n",
      "[I 2025-05-30 23:43:04,057] Trial 3 finished with value: 0.38888888888888884 and parameters: {'xgb_n_estimators': 346, 'xgb_max_depth': 5, 'xgb_lr': 0.0018770603531118371, 'xgb_subsample': 0.5133575963581991, 'xgb_cbt': 0.3555945737798747, 'xgb_alpha': 0.00041569173390582786, 'xgb_lambda': 1.3949810463844323e-08, 'brf_n_estimators': 1766, 'brf_max_depth': 19, 'brf_min_samples_split': 17, 'brf_min_samples_leaf': 8, 'brf_bootstrap': True}. Best is trial 1 with value: 0.4065656565656566.\n",
      "[I 2025-05-30 23:43:10,092] Trial 4 finished with value: 0.4305555555555556 and parameters: {'xgb_n_estimators': 651, 'xgb_max_depth': 13, 'xgb_lr': 0.19380278122876948, 'xgb_subsample': 0.5095447132652063, 'xgb_cbt': 0.7650260903417199, 'xgb_alpha': 0.14632040814423844, 'xgb_lambda': 3.387865462590279e-08, 'brf_n_estimators': 1296, 'brf_max_depth': 28, 'brf_min_samples_split': 5, 'brf_min_samples_leaf': 6, 'brf_bootstrap': False}. Best is trial 4 with value: 0.4305555555555556.\n",
      "[I 2025-05-30 23:43:14,666] Trial 5 finished with value: 0.428030303030303 and parameters: {'xgb_n_estimators': 752, 'xgb_max_depth': 15, 'xgb_lr': 0.40577485020521653, 'xgb_subsample': 0.7201155599402178, 'xgb_cbt': 0.5102580085523777, 'xgb_alpha': 0.0012801246198312023, 'xgb_lambda': 5.095585935644102e-07, 'brf_n_estimators': 922, 'brf_max_depth': 26, 'brf_min_samples_split': 5, 'brf_min_samples_leaf': 8, 'brf_bootstrap': False}. Best is trial 4 with value: 0.4305555555555556.\n",
      "[I 2025-05-30 23:43:20,884] Trial 6 finished with value: 0.422979797979798 and parameters: {'xgb_n_estimators': 608, 'xgb_max_depth': 9, 'xgb_lr': 0.07664373390946973, 'xgb_subsample': 0.5593453342989065, 'xgb_cbt': 0.9203798426148742, 'xgb_alpha': 0.0022593675245236363, 'xgb_lambda': 1.1708794845960486e-08, 'brf_n_estimators': 1492, 'brf_max_depth': 49, 'brf_min_samples_split': 8, 'brf_min_samples_leaf': 9, 'brf_bootstrap': False}. Best is trial 4 with value: 0.4305555555555556.\n",
      "[I 2025-05-30 23:43:31,338] Trial 7 finished with value: 0.4053030303030303 and parameters: {'xgb_n_estimators': 969, 'xgb_max_depth': 14, 'xgb_lr': 0.0013333178397970053, 'xgb_subsample': 0.9526091817140433, 'xgb_cbt': 0.9467365532968983, 'xgb_alpha': 2.4773630744788454e-06, 'xgb_lambda': 0.0002801616924952822, 'brf_n_estimators': 2485, 'brf_max_depth': 26, 'brf_min_samples_split': 18, 'brf_min_samples_leaf': 5, 'brf_bootstrap': False}. Best is trial 4 with value: 0.4305555555555556.\n",
      "[I 2025-05-30 23:43:35,949] Trial 8 finished with value: 0.3977272727272727 and parameters: {'xgb_n_estimators': 245, 'xgb_max_depth': 9, 'xgb_lr': 0.0026698711190727958, 'xgb_subsample': 0.9390419139874391, 'xgb_cbt': 0.6863322613681606, 'xgb_alpha': 8.588189995213246e-05, 'xgb_lambda': 8.634698579953275e-05, 'brf_n_estimators': 683, 'brf_max_depth': 8, 'brf_min_samples_split': 3, 'brf_min_samples_leaf': 5, 'brf_bootstrap': False}. Best is trial 4 with value: 0.4305555555555556.\n",
      "[I 2025-05-30 23:43:40,516] Trial 9 finished with value: 0.39393939393939387 and parameters: {'xgb_n_estimators': 134, 'xgb_max_depth': 14, 'xgb_lr': 0.002445744955784969, 'xgb_subsample': 0.821343029477394, 'xgb_cbt': 0.3161808457497897, 'xgb_alpha': 5.398595742097124e-06, 'xgb_lambda': 0.0010529804666248462, 'brf_n_estimators': 672, 'brf_max_depth': 11, 'brf_min_samples_split': 17, 'brf_min_samples_leaf': 5, 'brf_bootstrap': False}. Best is trial 4 with value: 0.4305555555555556.\n",
      "[I 2025-05-30 23:43:44,422] Trial 10 finished with value: 0.433080808080808 and parameters: {'xgb_n_estimators': 574, 'xgb_max_depth': 11, 'xgb_lr': 0.05573729746969105, 'xgb_subsample': 0.665493747352475, 'xgb_cbt': 0.7537769123446141, 'xgb_alpha': 1.0011046602062752, 'xgb_lambda': 2.5178873768594987e-06, 'brf_n_estimators': 153, 'brf_max_depth': 36, 'brf_min_samples_split': 2, 'brf_min_samples_leaf': 1, 'brf_bootstrap': False}. Best is trial 10 with value: 0.433080808080808.\n",
      "[I 2025-05-30 23:43:48,233] Trial 11 finished with value: 0.4343434343434343 and parameters: {'xgb_n_estimators': 577, 'xgb_max_depth': 11, 'xgb_lr': 0.05541144715185518, 'xgb_subsample': 0.6557924893148565, 'xgb_cbt': 0.772152582240513, 'xgb_alpha': 1.1386696739297162, 'xgb_lambda': 7.32669177199212e-06, 'brf_n_estimators': 282, 'brf_max_depth': 37, 'brf_min_samples_split': 2, 'brf_min_samples_leaf': 1, 'brf_bootstrap': False}. Best is trial 11 with value: 0.4343434343434343.\n",
      "[I 2025-05-30 23:43:51,382] Trial 12 finished with value: 0.422979797979798 and parameters: {'xgb_n_estimators': 450, 'xgb_max_depth': 11, 'xgb_lr': 0.018348784460429975, 'xgb_subsample': 0.6832401744601868, 'xgb_cbt': 0.7929702558767352, 'xgb_alpha': 1.3192255546375697, 'xgb_lambda': 5.031455412950159e-06, 'brf_n_estimators': 105, 'brf_max_depth': 37, 'brf_min_samples_split': 3, 'brf_min_samples_leaf': 1, 'brf_bootstrap': False}. Best is trial 11 with value: 0.4343434343434343.\n",
      "[I 2025-05-30 23:43:55,943] Trial 13 finished with value: 0.43686868686868685 and parameters: {'xgb_n_estimators': 765, 'xgb_max_depth': 11, 'xgb_lr': 0.02542603138170506, 'xgb_subsample': 0.6480191848341129, 'xgb_cbt': 0.8085782276358953, 'xgb_alpha': 1.8806364320147058e-08, 'xgb_lambda': 4.5958248944322875e-06, 'brf_n_estimators': 175, 'brf_max_depth': 36, 'brf_min_samples_split': 2, 'brf_min_samples_leaf': 1, 'brf_bootstrap': False}. Best is trial 13 with value: 0.43686868686868685.\n",
      "[I 2025-05-30 23:44:00,716] Trial 14 finished with value: 0.42676767676767674 and parameters: {'xgb_n_estimators': 783, 'xgb_max_depth': 11, 'xgb_lr': 0.013694475403882718, 'xgb_subsample': 0.6145944526242707, 'xgb_cbt': 0.8455387156798937, 'xgb_alpha': 2.4477387538437324e-08, 'xgb_lambda': 2.248748792089953e-05, 'brf_n_estimators': 396, 'brf_max_depth': 36, 'brf_min_samples_split': 6, 'brf_min_samples_leaf': 3, 'brf_bootstrap': False}. Best is trial 13 with value: 0.43686868686868685.\n",
      "[I 2025-05-30 23:44:14,220] Trial 15 finished with value: 0.4305555555555556 and parameters: {'xgb_n_estimators': 766, 'xgb_max_depth': 7, 'xgb_lr': 0.013108920373005357, 'xgb_subsample': 0.8534425038601375, 'xgb_cbt': 0.64553648276589, 'xgb_alpha': 1.1278540878046144e-08, 'xgb_lambda': 0.004928589392235012, 'brf_n_estimators': 2981, 'brf_max_depth': 41, 'brf_min_samples_split': 7, 'brf_min_samples_leaf': 3, 'brf_bootstrap': False}. Best is trial 13 with value: 0.43686868686868685.\n",
      "[I 2025-05-30 23:44:17,874] Trial 16 finished with value: 0.42424242424242425 and parameters: {'xgb_n_estimators': 512, 'xgb_max_depth': 3, 'xgb_lr': 0.09943581921057827, 'xgb_subsample': 0.6165404568957806, 'xgb_cbt': 0.6398111209967633, 'xgb_alpha': 0.04975383839523407, 'xgb_lambda': 1.9712345796267926e-05, 'brf_n_estimators': 491, 'brf_max_depth': 32, 'brf_min_samples_split': 13, 'brf_min_samples_leaf': 3, 'brf_bootstrap': False}. Best is trial 13 with value: 0.43686868686868685.\n",
      "[I 2025-05-30 23:44:27,250] Trial 17 finished with value: 0.433080808080808 and parameters: {'xgb_n_estimators': 852, 'xgb_max_depth': 10, 'xgb_lr': 0.03335599638372901, 'xgb_subsample': 0.7403458639221747, 'xgb_cbt': 0.8459635114674428, 'xgb_alpha': 1.800715052611783e-07, 'xgb_lambda': 2.297978184352633e-07, 'brf_n_estimators': 1845, 'brf_max_depth': 20, 'brf_min_samples_split': 2, 'brf_min_samples_leaf': 2, 'brf_bootstrap': False}. Best is trial 13 with value: 0.43686868686868685.\n",
      "[I 2025-05-30 23:44:32,696] Trial 18 finished with value: 0.4204545454545454 and parameters: {'xgb_n_estimators': 664, 'xgb_max_depth': 12, 'xgb_lr': 0.9858358716007048, 'xgb_subsample': 0.6825122009746227, 'xgb_cbt': 0.9908540931411454, 'xgb_alpha': 2.7243287302950153e-07, 'xgb_lambda': 4.4387150199038885, 'brf_n_estimators': 952, 'brf_max_depth': 41, 'brf_min_samples_split': 13, 'brf_min_samples_leaf': 2, 'brf_bootstrap': True}. Best is trial 13 with value: 0.43686868686868685.\n",
      "[I 2025-05-30 23:44:36,628] Trial 19 finished with value: 0.42045454545454547 and parameters: {'xgb_n_estimators': 500, 'xgb_max_depth': 8, 'xgb_lr': 0.009022472825073428, 'xgb_subsample': 0.8739314585310871, 'xgb_cbt': 0.7221285605167265, 'xgb_alpha': 0.00012896289361084145, 'xgb_lambda': 4.6618569835207505e-06, 'brf_n_estimators': 302, 'brf_max_depth': 31, 'brf_min_samples_split': 4, 'brf_min_samples_leaf': 4, 'brf_bootstrap': False}. Best is trial 13 with value: 0.43686868686868685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "{'xgb_n_estimators': 765, 'xgb_max_depth': 11, 'xgb_lr': 0.02542603138170506, 'xgb_subsample': 0.6480191848341129, 'xgb_cbt': 0.8085782276358953, 'xgb_alpha': 1.8806364320147058e-08, 'xgb_lambda': 4.5958248944322875e-06, 'brf_n_estimators': 175, 'brf_max_depth': 36, 'brf_min_samples_split': 2, 'brf_min_samples_leaf': 1, 'brf_bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    xgb_params_trial = {\n",
    "        'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_loguniform('xgb_lr', 1e-3, 1.0),\n",
    "        'subsample': trial.suggest_uniform('xgb_subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('xgb_cbt', 0.3, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('xgb_alpha', 1e-8, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('xgb_lambda', 1e-8, 10.0),\n",
    "        'tree_method': 'hist',\n",
    "        'objective': 'multi:softprob',\n",
    "        'verbosity': 0,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    brf_params_trial = {\n",
    "        'n_estimators': trial.suggest_int('brf_n_estimators', 100, 3000),\n",
    "        'max_depth': trial.suggest_int('brf_max_depth', 5, 50),\n",
    "        'min_samples_split': trial.suggest_int('brf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('brf_min_samples_leaf', 1, 10),\n",
    "        'bootstrap': trial.suggest_categorical('brf_bootstrap', [True, False]),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    clf = VotingClassifier(estimators=[\n",
    "        ('bnb1', BernoulliNB(alpha=0.01)),\n",
    "        ('bnb2', BernoulliNB(alpha=1.2)),\n",
    "        ('bnb3', BernoulliNB(alpha=2)),\n",
    "        ('lr',   LogisticRegression(max_iter=10000, random_state=42, n_jobs=-1)),\n",
    "        ('xgb',  XGBClassifier(**xgb_params_trial)),\n",
    "        ('brf',  BalancedRandomForestClassifier(**brf_params_trial)),\n",
    "        ('rf1',  RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)),\n",
    "        ('rf2',  RandomForestClassifier(n_estimators=300, max_depth=30, random_state=42)),\n",
    "        ('rf3',  RandomForestClassifier(\n",
    "            n_estimators=280, max_depth=30,\n",
    "            min_samples_leaf=1, min_samples_split=11,\n",
    "            bootstrap=False, random_state=42\n",
    "        )),\n",
    "    ], voting='soft', n_jobs=-1)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(clf, X_scaled_df, y_resampled, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20, timeout=600)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "4aefe811",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "\n",
    "best_xgb = XGBClassifier(\n",
    "    n_estimators=best_params['xgb_n_estimators'],\n",
    "    max_depth=best_params['xgb_max_depth'],\n",
    "    learning_rate=best_params['xgb_lr'],\n",
    "    subsample=best_params['xgb_subsample'],\n",
    "    colsample_bytree=best_params['xgb_cbt'],\n",
    "    reg_alpha=best_params['xgb_alpha'],\n",
    "    reg_lambda=best_params['xgb_lambda'],\n",
    "    tree_method='hist', objective='multi:softprob',\n",
    "    verbosity=0, n_jobs=-1, random_state=42\n",
    ")\n",
    "best_brf = BalancedRandomForestClassifier(\n",
    "    n_estimators=best_params['brf_n_estimators'],\n",
    "    max_depth=best_params['brf_max_depth'],\n",
    "    min_samples_split=best_params['brf_min_samples_split'],\n",
    "    min_samples_leaf=best_params['brf_min_samples_leaf'],\n",
    "    bootstrap=best_params['brf_bootstrap'],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "47c2c7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;bnb1&#x27;, BernoulliNB(alpha=0.01)),\n",
       "                             (&#x27;bnb2&#x27;, BernoulliNB(alpha=1.2)),\n",
       "                             (&#x27;bnb3&#x27;, BernoulliNB(alpha=2)),\n",
       "                             (&#x27;lr&#x27;,\n",
       "                              LogisticRegression(max_iter=10000, n_jobs=-1,\n",
       "                                                 random_state=42)),\n",
       "                             (&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.8085782276358953,\n",
       "                                            device=None,...\n",
       "                              BalancedRandomForestClassifier(max_depth=36,\n",
       "                                                             n_estimators=175,\n",
       "                                                             random_state=42)),\n",
       "                             (&#x27;rf1&#x27;,\n",
       "                              RandomForestClassifier(max_depth=20,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;rf2&#x27;,\n",
       "                              RandomForestClassifier(max_depth=30,\n",
       "                                                     n_estimators=300,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;rf3&#x27;,\n",
       "                              RandomForestClassifier(bootstrap=False,\n",
       "                                                     max_depth=30,\n",
       "                                                     min_samples_split=11,\n",
       "                                                     n_estimators=280,\n",
       "                                                     random_state=42))],\n",
       "                 n_jobs=-1, voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>VotingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>VotingClassifier(estimators=[(&#x27;bnb1&#x27;, BernoulliNB(alpha=0.01)),\n",
       "                             (&#x27;bnb2&#x27;, BernoulliNB(alpha=1.2)),\n",
       "                             (&#x27;bnb3&#x27;, BernoulliNB(alpha=2)),\n",
       "                             (&#x27;lr&#x27;,\n",
       "                              LogisticRegression(max_iter=10000, n_jobs=-1,\n",
       "                                                 random_state=42)),\n",
       "                             (&#x27;xgb&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.8085782276358953,\n",
       "                                            device=None,...\n",
       "                              BalancedRandomForestClassifier(max_depth=36,\n",
       "                                                             n_estimators=175,\n",
       "                                                             random_state=42)),\n",
       "                             (&#x27;rf1&#x27;,\n",
       "                              RandomForestClassifier(max_depth=20,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;rf2&#x27;,\n",
       "                              RandomForestClassifier(max_depth=30,\n",
       "                                                     n_estimators=300,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;rf3&#x27;,\n",
       "                              RandomForestClassifier(bootstrap=False,\n",
       "                                                     max_depth=30,\n",
       "                                                     min_samples_split=11,\n",
       "                                                     n_estimators=280,\n",
       "                                                     random_state=42))],\n",
       "                 n_jobs=-1, voting=&#x27;soft&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>bnb1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BernoulliNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.BernoulliNB.html\">?<span>Documentation for BernoulliNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>BernoulliNB(alpha=0.01)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>bnb2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BernoulliNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.BernoulliNB.html\">?<span>Documentation for BernoulliNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>BernoulliNB(alpha=1.2)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>bnb3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BernoulliNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.BernoulliNB.html\">?<span>Documentation for BernoulliNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>BernoulliNB(alpha=2)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=10000, n_jobs=-1, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8085782276358953, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02542603138170506,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=765, n_jobs=-1,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>brf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BalancedRandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>BalancedRandomForestClassifier(max_depth=36, n_estimators=175, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=20, n_estimators=200, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=30, n_estimators=300, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(bootstrap=False, max_depth=30, min_samples_split=11,\n",
       "                       n_estimators=280, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('bnb1', BernoulliNB(alpha=0.01)),\n",
       "                             ('bnb2', BernoulliNB(alpha=1.2)),\n",
       "                             ('bnb3', BernoulliNB(alpha=2)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(max_iter=10000, n_jobs=-1,\n",
       "                                                 random_state=42)),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.8085782276358953,\n",
       "                                            device=None,...\n",
       "                              BalancedRandomForestClassifier(max_depth=36,\n",
       "                                                             n_estimators=175,\n",
       "                                                             random_state=42)),\n",
       "                             ('rf1',\n",
       "                              RandomForestClassifier(max_depth=20,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=42)),\n",
       "                             ('rf2',\n",
       "                              RandomForestClassifier(max_depth=30,\n",
       "                                                     n_estimators=300,\n",
       "                                                     random_state=42)),\n",
       "                             ('rf3',\n",
       "                              RandomForestClassifier(bootstrap=False,\n",
       "                                                     max_depth=30,\n",
       "                                                     min_samples_split=11,\n",
       "                                                     n_estimators=280,\n",
       "                                                     random_state=42))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_clf = VotingClassifier(estimators=[\n",
    "    ('bnb1', BernoulliNB(alpha=0.01)),\n",
    "    ('bnb2', BernoulliNB(alpha=1.2)),\n",
    "    ('bnb3', BernoulliNB(alpha=2)),\n",
    "    ('lr',   LogisticRegression(max_iter=10000, random_state=42, n_jobs=-1)),\n",
    "    ('xgb',  best_xgb),\n",
    "    ('brf',  best_brf),\n",
    "    ('rf1',  RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)),\n",
    "    ('rf2',  RandomForestClassifier(n_estimators=300, max_depth=30, random_state=42)),\n",
    "    ('rf3',  RandomForestClassifier(\n",
    "        n_estimators=280, max_depth=30,\n",
    "        min_samples_leaf=1, min_samples_split=11,\n",
    "        bootstrap=False, random_state=42\n",
    "    )),\n",
    "], voting='soft', n_jobs=-1)\n",
    "\n",
    "final_clf.fit(X_scaled_df, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c6d9aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_clf.predict(pd.DataFrame(test).drop('index', axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f516f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ae6e90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "42afd619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  0\n",
       "0        0  0\n",
       "1        1  8\n",
       "2        2  7\n",
       "3        3  3\n",
       "4        4  0\n",
       "..     ... ..\n",
       "138    138  8\n",
       "139    139  1\n",
       "140    140  0\n",
       "141    141  9\n",
       "142    142  1\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv('sub1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
